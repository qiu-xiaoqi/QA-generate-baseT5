{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, get_scheduler\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路径及参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./DuReaderQG/train.json\"\n",
    "test_path = \"./DuReaderQG/dev.json\"\n",
    "max_target_len = 32\n",
    "max_source_len = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 16\n",
    "lr = 5e-5\n",
    "save_path = \"./checkpoints/\"\n",
    "num_train_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载model和tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BertTokenizerFast(name_or_path='./uer/t5-base-chinese-cluecorpussmall', vocab_size=21229, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " T5ForConditionalGeneration(\n",
       "   (shared): Embedding(21228, 768)\n",
       "   (encoder): T5Stack(\n",
       "     (embed_tokens): Embedding(21228, 768)\n",
       "     (block): ModuleList(\n",
       "       (0): T5Block(\n",
       "         (layer): ModuleList(\n",
       "           (0): T5LayerSelfAttention(\n",
       "             (SelfAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (relative_attention_bias): Embedding(32, 12)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): T5LayerFF(\n",
       "             (DenseReluDense): T5DenseActDense(\n",
       "               (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "               (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "               (act): ReLU()\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1-11): 11 x T5Block(\n",
       "         (layer): ModuleList(\n",
       "           (0): T5LayerSelfAttention(\n",
       "             (SelfAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): T5LayerFF(\n",
       "             (DenseReluDense): T5DenseActDense(\n",
       "               (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "               (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "               (act): ReLU()\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (final_layer_norm): T5LayerNorm()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (decoder): T5Stack(\n",
       "     (embed_tokens): Embedding(21228, 768)\n",
       "     (block): ModuleList(\n",
       "       (0): T5Block(\n",
       "         (layer): ModuleList(\n",
       "           (0): T5LayerSelfAttention(\n",
       "             (SelfAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (relative_attention_bias): Embedding(32, 12)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): T5LayerCrossAttention(\n",
       "             (EncDecAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): T5LayerFF(\n",
       "             (DenseReluDense): T5DenseActDense(\n",
       "               (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "               (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "               (act): ReLU()\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1-11): 11 x T5Block(\n",
       "         (layer): ModuleList(\n",
       "           (0): T5LayerSelfAttention(\n",
       "             (SelfAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): T5LayerCrossAttention(\n",
       "             (EncDecAttention): T5Attention(\n",
       "               (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "               (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): T5LayerFF(\n",
       "             (DenseReluDense): T5DenseActDense(\n",
       "               (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "               (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "               (act): ReLU()\n",
       "             )\n",
       "             (layer_norm): T5LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (final_layer_norm): T5LayerNorm()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (lm_head): Linear(in_features=768, out_features=21228, bias=False)\n",
       " ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pertrained_path = './uer/t5-base-chinese-cluecorpussmall'\n",
    "tokenizer = AutoTokenizer.from_pretrained(pertrained_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(pertrained_path)\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = []\n",
    "        with open(data_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                self.data.append(json.loads(line))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        input_seq = (f\"问题：{item['question']}{tokenizer.sep_token}原文：{item['context']}\")\n",
    "        output_seq = f\"答案：{item['answer']}{tokenizer.eos_token}\"\n",
    "        return input_seq, output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('问题：仙剑奇侠传3第几集上天界[SEP]原文：第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。',\n",
       " '答案：第35集None')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = QADataset(train_path)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     test_train\u001b[38;5;241m.\u001b[39mappend(train_dataset[i]) \n\u001b[0;32m     31\u001b[0m train_test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mtrain_test_dataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    batched_data = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"decoder_input_ids\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    for _, (input_seq, output_seq) in enumerate(batch):\n",
    "        # tokenize输入\n",
    "        inputs = tokenizer(text=input_seq, truncation=True, max_length=max_source_len, padding=True)\n",
    "       \n",
    "        # tokenize输出,并将输出的ids作为inputs的label\n",
    "        output_ids = tokenizer.encode(text=output_seq, truncation=True, max_length=max_target_len)\n",
    "        decoder_input_ids = output_ids[:-2] # 去掉eos和[cls]\n",
    "        decoder_input_ids =  decoder_input_ids + [tokenizer.pad_token_id] * (max_target_len - len(decoder_input_ids)) # padding\n",
    "        \n",
    "        labels = output_ids[1: -1] # 去掉起始token和[cls]\n",
    "        labels = labels + [-100] * (max_target_len - len(labels))\n",
    "        \n",
    "        batched_data[\"input_ids\"].append(inputs[\"input_ids\"])\n",
    "        batched_data[\"attention_mask\"].append(inputs[\"attention_mask\"])\n",
    "        batched_data[\"decoder_input_ids\"].append(decoder_input_ids)\n",
    "        batched_data[\"labels\"].append(labels)\n",
    "        \n",
    "    for k, v in batched_data.items():\n",
    "        batched_data[k] = torch.tensor(np.array(v))\n",
    "    return batched_data\n",
    "\n",
    "test_train = []\n",
    "for i in range(5):\n",
    "    test_train.append(train_dataset[i]) \n",
    "\n",
    "train_test_dataloader = DataLoader(test_train, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "train_test_dataloader            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(value, name):\n",
    "    plt.figure()\n",
    "    plt.plot(value)\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(f\"{name}\")\n",
    "    plt.title(f\"{name}\")\n",
    "    plt.savefig(f\"log/{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_loader):\n",
    "    model.eval()\n",
    "    bleu1 = []\n",
    "    bleu2 = []\n",
    "    bleu3 = []\n",
    "    bleu4 = []\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    print(\"Evaluation\")\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(data_loader):\n",
    "            outputs = model.generate(\n",
    "                input_ids=batch[\"input_ids\"].to(device)\n",
    "            )\n",
    "            label_tokens = batch[\"labels\"].cpu().numpy()\n",
    "            decode_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            label_tokens = np.where(\n",
    "                batch[\"labels\"] != -100, label_tokens, tokenizer.pad_token_id\n",
    "            )\n",
    "            decode_labels = tokenizer.batch_decode(\n",
    "                label_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            for pred, ref in zip(decode_preds, decode_labels):\n",
    "                bleu1.append(\n",
    "                    sentence_bleu(\n",
    "                        [ref.split()],\n",
    "                        pred.split(),\n",
    "                        smoothing_function=smoothie,\n",
    "                        weights=(1, 0, 0, 0),\n",
    "                    )\n",
    "                )\n",
    "                bleu2.append(\n",
    "                    sentence_bleu(\n",
    "                        [ref.split()],\n",
    "                        pred.split(),\n",
    "                        smoothing_function=smoothie,\n",
    "                        weights=(0.5, 0.5, 0, 0),\n",
    "                    )\n",
    "                )\n",
    "                bleu3.append(\n",
    "                    sentence_bleu(\n",
    "                        [ref.split()],\n",
    "                        pred.split(),\n",
    "                        smoothing_function=smoothie,\n",
    "                        weights=(0.33, 0.33, 0.33, 0),\n",
    "                    )\n",
    "                )\n",
    "                bleu4.append(\n",
    "                    sentence_bleu(\n",
    "                        [ref.split()],\n",
    "                        pred.split(),\n",
    "                        smoothing_function=smoothie,\n",
    "                        weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                    )\n",
    "                )\n",
    "    model.train()  \n",
    "    return [\n",
    "        sum(bleu1) / len(bleu1),\n",
    "        sum(bleu2) / len(bleu2),\n",
    "        sum(bleu3) / len(bleu3),  \n",
    "        sum(bleu4) / len(bleu4),\n",
    "    ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_train_epochs, train_loader, model, optimizer, lr_scheduler, device, logging_steps, loss_list, global_step, tic_train):\n",
    "    for epoch in range(num_train_epochs):\n",
    "        for batch in train_loader:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(device),\n",
    "                decoder_input_ids=batch[\"decoder_input_ids\"].to(device),\n",
    "                labels=batch[\"labels\"].to(device),\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_list.append(float(loss.cpu().detach()))\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % logging_steps == 0:\n",
    "                time_diff = time.time() - tic_train\n",
    "                loss_avg = sum(loss_list) / len(loss_list)\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, loss_avg, logging_steps / time_diff)\n",
    "                )\n",
    "                tic_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_loop():\n",
    "    tokenizer.eos_token = tokenizer.sep_token\n",
    "    tokenizer.bos_token = tokenizer.cls_token\n",
    "\n",
    "    train_dataset = QADataset(data_path=train_path)\n",
    "    test_dataset = QADataset(data_path=test_path)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_epochs * len(train_loader),\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    loss_list = []\n",
    "    bleu1 = []\n",
    "    bleu2 = []\n",
    "    bleu3 = []\n",
    "    bleu4 = []\n",
    "    tic_train = time.time()\n",
    "    global_step, best_bleu4 = 0, 0\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "        train(num_train_epochs, train_loader, model, optimizer, lr_scheduler, device, logging_steps, loss_list, global_step, tic_train)\n",
    "        # 在每个epoch结束后评估模型\n",
    "        bleu_scores = evaluate_model(test_loader)\n",
    "        print(f\"Epoch {epoch}, BLEU-1: {bleu_scores[0]}, BLEU-2: {bleu_scores[1]}, BLEU-3: {bleu_scores[2]}, BLEU-4: {bleu_scores[3]}\")\n",
    "        if bleu_scores[3] > best_bleu4:\n",
    "            best_bleu4 = bleu_scores[3]\n",
    "            torch.save(model.state_dict(), f\"{save_path}/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
